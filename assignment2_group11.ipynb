{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNY66pKKQb1e"
      },
      "source": [
        "# ENEL 645 Assignment 2\n",
        "Group 11 Team Members: Steven Au, Laurel Flanagan, Rhys Wickens, Austen Zhang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "A custom MultiModal neural network was built. For images, EfficientNetV2s was used for feature extraction. For text data, DistilBERT uncased was used for feature extraction. After feature extraction, the outputs from each Neural Network are concatenated into one feature vector which contains both text and image information. This is then passed through a classification layer to make predictions. \n",
        "\n",
        "To train our model, we used a training loop which saves the best model and waits 10 epochs until stopping training. We found that our model triggered early stopping at epoch 13, taking 5640 seconds. Our Multimodal model produced a test accuracy of 88.1%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment Setup\n",
        "\n",
        "This experiment aims to train a MultiModal model for garbage classification, to help Calgarians properly dispose of waste into green, blue, black or other bins. This dataset was provided by Dr. Robert Souza as part of the ENEL645 course. The data was pre-split into train, validation, and test sets, composing of 11,629 samples in the train set, 1800 samples in the validation set, and 2346 samples in the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experimental Process\n",
        "\n",
        "As part of the experimentation process, we set up Weights and Biases to monitor model performance. To select the model for image feature extraction, we trained MobileNetV2, and EfficientNetV2s with a single classification layer. We found that EfficientNetV2s, given the same amount of epochs, batch size, and learning rate, trained faster than MobileNetV2. EfficientNetV2s also out performed MobileNetV2s when comparing test accuracies, with MobileNetV2 scoring 66.4% and EfficientNetV2s scoring slightly higher at 68.4%. \n",
        "\n",
        "To select the model for text feature extraction, we trained ALBERT and DistilBERT Uncased. Given the same amount of epochs, batch size, learning rate and drop out, ALBERT scored a test accuracy of 83% and DistilBERT scored higher at 88.9%.\n",
        "\n",
        "After selecting models, a hyperparameter search was performed to find a learning rate for each model, and a unified batch_size suitable for both models. We selected a batch size of 128 for the MultiModal model, based on the observation that the validation accuracy appeared to have the highest chance of converging over a smaller number of epochs.\n",
        "\n",
        "Each model was used in parallel to build the Multimodal model, which processes the input text and dataset. The Multimodal model concatenates the features extracted by EfficientNetV2s and DistilBERT. The results from the feature extraction are joined into a vector which contains the extracted features, and is passed through a prediction layer with dropout to improve model generalization.\n",
        "\n",
        "For the same hyperparameters, we found that EfficientNetV2s had a test accuracy of 75.9%. For text feature extraction, we found that DistilBERT had a test accuracy of 85.0% for the same set of hyperparemeters in our Multimodal model. Fusing the two models resulted in a test accuracy of 88.1%, which outperforms the highest test accuracy of the individual feature extraction models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMLOOi0GQM5B"
      },
      "source": [
        "## Garbage Classification Transfer Learning\n",
        "Pre-trained Model: Efficient Net V2 S (https://pytorch.org/vision/main/models/generated/torchvision.models.efficientnet_v2_s.html#torchvision.models.efficientnet_v2_s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV8_lUSaP4Di"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "import wandb\n",
        "\n",
        "# ========================================= GLOBAL CONFIGURATION ================================================\n",
        "# Data Directories\n",
        "DATA_DIR = r\"C:\\NN Data\\garbage_data\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"CVPR_2024_dataset_Train\")\n",
        "VAL_DIR = os.path.join(DATA_DIR, \"CVPR_2024_dataset_Val\")\n",
        "TEST_DIR = os.path.join(DATA_DIR, \"CVPR_2024_dataset_Test\")\n",
        "\n",
        "# Model and Training Configuration\n",
        "MODEL_NAME = \"efficientnetv2s_distilbert_multimodal\"\n",
        "IMAGE_SIZE = (384, 384) # Image size\n",
        "NUM_WORKERS = 4 # Parallel data loading processes\n",
        "NUM_CLASSES = 4 # For prediction layer\n",
        "BATCH_SIZE = 128 # Number of samples\n",
        "MAX_LEN = 24 # For DistilBERT\n",
        "EPOCHS = 50 # Max epochs\n",
        "LEARNING_RATE_EFFICIENTNET = 0.001 # EfficientNetV2s\n",
        "LEARNING_RATE_DISTILBERT = 0.0001 # DistilBERT Uncased\n",
        "DROPOUT = 0.3 # For DistilBERT \n",
        "CONVERGENCE_THRESHOLD = 0.001  # Minimum improvement in validation loss\n",
        "PATIENCE = 10 # Number of epochs to wait for improvement\n",
        "\n",
        "# Wandb Configuration\n",
        "WANDB_CONFIG = {\n",
        "    \"entity\": \"shcau-university-of-calgary-in-alberta\",\n",
        "    \"project\": \"transfer_learning_garbage\",\n",
        "    \"name\": \"Multimodal_Model_Train_Model\",\n",
        "    \"tags\": [\"distilBERT\", \"efficientnet\", \"CVPR_2024_dataset\"],\n",
        "    \"notes\": \"Assignment 2 Train Model\",\n",
        "    \"config\": {\"epochs\": EPOCHS, \"batch_size\": BATCH_SIZE, \"dataset\": \"CVPR_2024_dataset\"},\n",
        "    \"job_type\": \"train\",\n",
        "    \"resume\": \"allow\",\n",
        "}\n",
        "\n",
        "# Normalization Stats\n",
        "NORMALIZATION_STATS = {\n",
        "    \"mean\": [0.485, 0.456, 0.406],\n",
        "    \"std\": [0.229, 0.224, 0.225],\n",
        "}\n",
        "\n",
        "# ========================================= HELPER FUNCTIONS ================================================\n",
        "# Initialize wandb\n",
        "def initialize_wandb():\n",
        "    if wandb.run is None:\n",
        "        wandb.init(**WANDB_CONFIG)\n",
        "\n",
        "# Extract text from file names as well as labels\n",
        "def read_text_files_with_labels(path):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    class_folders = sorted(os.listdir(path))\n",
        "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            file_names = os.listdir(class_path)\n",
        "            for file_name in file_names:\n",
        "                file_path = os.path.join(class_path, file_name)\n",
        "                if os.path.isfile(file_path):\n",
        "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
        "                    text = file_name_no_ext.replace('_', ' ')\n",
        "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
        "                    texts.append(text_without_digits)\n",
        "                    labels.append(label_map[class_name])\n",
        "\n",
        "    return np.array(texts), np.array(labels)\n",
        "\n",
        "# ========================================= DATASET CLASSES ================================================\n",
        "class CustomTextDataset(Dataset): # Initializes text dataset\n",
        "    def __init__(self, texts, labels, tokenizer, max_len):\n",
        "        self.texts = texts # stores a list of text samples\n",
        "        self.labels = labels # stores list of corresponding labels\n",
        "        self.tokenizer = tokenizer # DistilBERT tokenizer\n",
        "        self.max_len = max_len # Maximum length for tokenized sequences (MAX_LEN = 24)\n",
        "\n",
        "    def __len__(self): # Returns number of samples\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx): # Retrieves sample by index `idx`\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus( # Tokenize text\n",
        "            text,\n",
        "            add_special_tokens=True, # Add special tokens to separate text input\n",
        "            max_length=self.max_len, # Truncates or pads the sequence to max_len\n",
        "            return_token_type_ids=False, # Does not return token type IDs\n",
        "            padding='max_length', # Pad text to max length\n",
        "            truncation=True, # Truncates text sample if exceeds max_len = 24\n",
        "            return_attention_mask=True, # Return attention mask to pay attention to token and not padding tokens\n",
        "            return_tensors='pt' # Return PyTorch tensor\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'text': text,\n",
        "            'input_ids': encoding['input_ids'].flatten(), # Flatten input sample tensor\n",
        "            'attention_mask': encoding['attention_mask'].flatten(), # Flatten attention mask\n",
        "            'label': torch.tensor(label, dtype=torch.long) # Convert label to PyTorch tensor\n",
        "        }\n",
        "\n",
        "# MultimodalDataset class to handle multimodal data \n",
        "class MultimodalDataset(Dataset): \n",
        "    def __init__(self, image_dataset, text_dataset):\n",
        "        self.image_dataset = image_dataset # Stores image dataset\n",
        "        self.text_dataset = text_dataset # Stores text dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.image_dataset), len(self.text_dataset))\n",
        "\n",
        "    def __getitem__(self, idx): # returns a sample containing both text and image data\n",
        "        image, label = self.image_dataset[idx]\n",
        "        text_data = self.text_dataset[idx]\n",
        "        return {\n",
        "            \"image\": image, \n",
        "            \"input_ids\": text_data[\"input_ids\"],\n",
        "            \"attention_mask\": text_data[\"attention_mask\"],\n",
        "            \"label\": label\n",
        "        }\n",
        "\n",
        "# ========================================= MODEL DEFINITION ================================================\n",
        "class MultimodalClassifier(nn.Module): # Build custom Neural Network using nn.Module\n",
        "    def __init__(self, num_classes):\n",
        "        super(MultimodalClassifier, self).__init__() # Call constructor parent class nn.Module\n",
        "\n",
        "        # EfficientNetV2s which extracts features from image data\n",
        "        self.image_model = models.efficientnet_v2_s(weights=models.EfficientNet_V2_S_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        # Freeze EfficientNetV2s feature layers\n",
        "        for param in self.image_model.features.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        num_ftrs = self.image_model.classifier[1].in_features\n",
        "\n",
        "        # Remove to make use of custom prediction layer\n",
        "        self.image_model.classifier = nn.Identity()\n",
        "\n",
        "        # Project features to 256 dimensions\n",
        "        self.image_fc = nn.Linear(num_ftrs, 256)\n",
        "\n",
        "        # DistilBERT which extracts features from text data\n",
        "        self.text_model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "        self.text_fc = nn.Linear(self.text_model.config.hidden_size, 256)\n",
        "\n",
        "        # Normalization layers\n",
        "        self.text_norms = nn.LayerNorm(256)\n",
        "        self.image_norm = nn.LayerNorm(256)\n",
        "\n",
        "        # Feature fusion Layer (Concatenation)\n",
        "        self.fusion_fc = nn.Linear(512, self.text_model.config.hidden_size)\n",
        "\n",
        "        # Classification Layer\n",
        "        self.classifier = nn.Linear(self.text_model.config.hidden_size, num_classes)\n",
        "        self.dropout = nn.Dropout(0.3) # Apply dropout to learn only the more features (keep higher signals)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask, image_inputs):\n",
        "        # Extract text features\n",
        "        text_output = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        text_features = self.text_norms(self.text_fc(text_output.last_hidden_state[:, 0, :]))  # Extract sequence of token embeddings \n",
        "\n",
        "        # Extract image features\n",
        "        image_features = self.image_norm(self.image_fc(self.image_model(image_inputs)))\n",
        "\n",
        "        # Concatenate text and image features\n",
        "        combined_features = torch.cat((text_features, image_features), dim=1)\n",
        "\n",
        "        # Pass through fusion and classification layers\n",
        "        combined_features = self.fusion_fc(combined_features)\n",
        "        output = self.classifier(self.dropout(combined_features))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "# ========================================= EVALUATION FUNCTION ================================================\n",
        "def evaluate_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct, total = 0, 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            # Send data to GPU\n",
        "            images, input_ids, attention_mask, labels = batch[\"image\"].to(device), batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"label\"].to(device)\n",
        "            outputs = model(input_ids, attention_mask, images) # Forward pass\n",
        "            loss = criterion(outputs, labels) # Compute loss\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item() # Compute accuracy\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = correct / total # Calculate average loss and accuracy\n",
        "    return total_loss / len(dataloader), accuracy\n",
        "\n",
        "\n",
        "# ========================================= TRAINING LOOP ================================================\n",
        "def train_model(model, dataloaders, criterion, optimizer, device):\n",
        "    initialize_wandb() # Initialize W&B using configuration\n",
        "\n",
        "    wandb.watch(model, log=\"all\") # Log gradients and parameters\n",
        "    best_val_loss = float(\"inf\") # Track best validation loss\n",
        "    epochs_without_improvement = 0 # Track epochs without improvement until equals patience\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nStarting Epoch {epoch + 1}/{EPOCHS}\")\n",
        "        model.train() # Set model to training mode\n",
        "        total_train_loss = 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch in dataloaders[\"train_loader\"]:\n",
        "            # Move data to device\n",
        "            images, input_ids, attention_mask, labels = batch[\"image\"].to(device), batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"label\"].to(device)\n",
        "            optimizer.zero_grad() # Zero gradients to prevent Gradient Accumulation across batches\n",
        "            outputs = model(input_ids, attention_mask, images) # Send inputs to network and receive outputs\n",
        "            loss = criterion(outputs, labels) # Calculate loss function for this batch\n",
        "            loss.backward() # Back propogate to compute the gradient for each parameter and update model weights\n",
        "            optimizer.step() # Take a step in the direction and update weight coefficients to minimize loss function\n",
        "            total_train_loss += loss.item() # Track loss\n",
        "\n",
        "        # Validation step to see how well model performs this epoch\n",
        "        val_loss, val_acc = evaluate_model(model, dataloaders[\"val_loader\"], device)\n",
        "        \n",
        "        # Log metrics of this epoch to wandb\n",
        "        wandb.log({\"epoch\": epoch+1, \"train_loss\": total_train_loss, \"val_loss\": val_loss, \"val_accuracy\": val_acc})\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}, Train Loss: {total_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "        # Check for improvement in validation loss\n",
        "        if val_loss < best_val_loss - CONVERGENCE_THRESHOLD:  # If loss improves, then we save the model\n",
        "            best_val_loss = val_loss\n",
        "            epochs_without_improvement = 0 # Reset epochs without improvement counter for patience\n",
        "            torch.save(model.state_dict(), \"best_multimodal_model.pth\") # Save model\n",
        "        else:\n",
        "            epochs_without_improvement += 1 # Increment until patience reached\n",
        "\n",
        "        # Early stopping if no improvement for epochs\n",
        "        if epochs_without_improvement >= PATIENCE:\n",
        "            print(f\"Early stopping at epoch {epoch + 1} as validation loss did not improve for {PATIENCE} epochs.\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define transformations\n",
        "transform = {\n",
        "    \"train\": transforms.Compose([\n",
        "        models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(), # pre-trained EfficientNetV2s image normalization\n",
        "        transforms.RandomHorizontalFlip(), # Applies random horizontal flip\n",
        "    ]),\n",
        "    \"val\": models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(), # Normalize the validation set (no transformations)\n",
        "    \"test\": models.EfficientNet_V2_S_Weights.IMAGENET1K_V1.transforms(), # Normalize the test set (no transformations)\n",
        "}\n",
        "\n",
        "# Load dataset and apply transformations\n",
        "image_datasets = {\n",
        "    \"train\": datasets.ImageFolder(TRAIN_DIR, transform=transform[\"train\"]), # \n",
        "    \"val\": datasets.ImageFolder(VAL_DIR, transform=transform[\"val\"]),\n",
        "    \"test\": datasets.ImageFolder(TEST_DIR, transform=transform[\"test\"]),\n",
        "}\n",
        "\n",
        "# Read text data and corresponding labels\n",
        "text_train, labels_train = read_text_files_with_labels(TRAIN_DIR)\n",
        "text_val, labels_val = read_text_files_with_labels(VAL_DIR)\n",
        "text_test, labels_test = read_text_files_with_labels(TEST_DIR)\n",
        "\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased') # Loads pre-trained DistilBERT tokenizer\n",
        "\n",
        "# Create PyTorch dataloaders to provide batches of image and text data, used for training and evaluation\n",
        "dataloaders = {\n",
        "    \"train_loader\" : DataLoader(MultimodalDataset(image_datasets[\"train\"], CustomTextDataset(text_train, labels_train, tokenizer, MAX_LEN)), \n",
        "                            batch_size=BATCH_SIZE, shuffle=True),\n",
        "    \"val_loader\" : DataLoader(MultimodalDataset(image_datasets[\"val\"], CustomTextDataset(text_val, labels_val, tokenizer, MAX_LEN)), \n",
        "                        batch_size=BATCH_SIZE, shuffle=False),\n",
        "    \"test_loader\" : DataLoader(MultimodalDataset(image_datasets[\"test\"], CustomTextDataset(text_test, labels_test, tokenizer, MAX_LEN)), \n",
        "                        batch_size=BATCH_SIZE, shuffle=False)}\n",
        "\n",
        "# Model Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Uses GPU Cuda cores\n",
        "model = MultimodalClassifier(num_classes=NUM_CLASSES).to(device)  # Initializes model and sends to GPU\n",
        "optimizer = optim.Adam([\n",
        "    {'params': model.text_model.parameters(), 'lr': LEARNING_RATE_DISTILBERT},  \n",
        "    {'params': model.image_fc.parameters(), 'lr': LEARNING_RATE_EFFICIENTNET},  \n",
        "    {'params': model.classifier.parameters(), 'lr': LEARNING_RATE_EFFICIENTNET}\n",
        "])\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "wandb: Currently logged in as: shcau (shcau-university-of-calgary-in-alberta) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n",
            "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\arkzs\\AppData\\GitHub Projects\\enel-645-a2\\wandb\\run-20250227_010230-6gj5nhoc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage/runs/6gj5nhoc' target=\"_blank\">Multimodal_Model_Train_Model</a></strong> to <a href='https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage' target=\"_blank\">https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage/runs/6gj5nhoc' target=\"_blank\">https://wandb.ai/shcau-university-of-calgary-in-alberta/transfer_learning_garbage/runs/6gj5nhoc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Epoch 1/50\n",
            "Epoch 1/50, Train Loss: 37.0911, Val Loss: 0.2359, Val Acc: 0.9261\n",
            "\n",
            "Starting Epoch 2/50\n",
            "Epoch 2/50, Train Loss: 15.9234, Val Loss: 0.2263, Val Acc: 0.9178\n",
            "\n",
            "Starting Epoch 3/50\n",
            "Epoch 3/50, Train Loss: 11.3538, Val Loss: 0.2225, Val Acc: 0.9217\n",
            "\n",
            "Starting Epoch 4/50\n",
            "Epoch 4/50, Train Loss: 8.3538, Val Loss: 0.2617, Val Acc: 0.9256\n",
            "\n",
            "Starting Epoch 5/50\n",
            "Epoch 5/50, Train Loss: 7.4434, Val Loss: 0.2631, Val Acc: 0.9322\n",
            "\n",
            "Starting Epoch 6/50\n",
            "Epoch 6/50, Train Loss: 5.7203, Val Loss: 0.2844, Val Acc: 0.9161\n",
            "\n",
            "Starting Epoch 7/50\n",
            "Epoch 7/50, Train Loss: 5.8741, Val Loss: 0.2972, Val Acc: 0.9300\n",
            "\n",
            "Starting Epoch 8/50\n",
            "Epoch 8/50, Train Loss: 4.2696, Val Loss: 0.3014, Val Acc: 0.9189\n",
            "\n",
            "Starting Epoch 9/50\n",
            "Epoch 9/50, Train Loss: 4.6774, Val Loss: 0.2989, Val Acc: 0.9272\n",
            "\n",
            "Starting Epoch 10/50\n",
            "Epoch 10/50, Train Loss: 4.4777, Val Loss: 0.2999, Val Acc: 0.9261\n",
            "\n",
            "Starting Epoch 11/50\n",
            "Epoch 11/50, Train Loss: 3.3456, Val Loss: 0.3286, Val Acc: 0.9239\n",
            "\n",
            "Starting Epoch 12/50\n",
            "Epoch 12/50, Train Loss: 3.5896, Val Loss: 0.3119, Val Acc: 0.9233\n",
            "\n",
            "Starting Epoch 13/50\n",
            "Epoch 13/50, Train Loss: 3.7528, Val Loss: 0.3813, Val Acc: 0.9278\n",
            "Early stopping at epoch 13 as validation loss did not improve for 10 epochs.\n"
          ]
        }
      ],
      "source": [
        "# Train model using model on device, PyTorch dataloaders, Adam optimizer, and GPU\n",
        "train_model(model, dataloaders, criterion, optimizer, device)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\arkzs\\AppData\\Local\\Temp\\ipykernel_32196\\1590263218.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"best_multimodal_model.pth\"))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.3438, Test Accuracy: 0.8811\n"
          ]
        }
      ],
      "source": [
        "# Load Best Model for Testing\n",
        "model.load_state_dict(torch.load(\"best_multimodal_model.pth\"))\n",
        "test_loss, test_acc = evaluate_model(model, dataloaders[\"test_loader\"], device)\n",
        "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")\n",
        "# wandb.log({\"test_accuracy\": test_acc})\n",
        "# wandb.finish()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "enel645_torch_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
